{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feels like temp!\n",
    "This example uses Met Office data point as the data source. It attempts to come up with a formular for predicting feels like temp based on the other parameters.\n",
    "\n",
    "The notebook requires you to have [a datapoint key](http://www.metoffice.gov.uk/datapoint/getting-started) fill it in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATAPOINT_KEY\"] = 'YOUR_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "import cPickle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helper import data_helpers\n",
    "from helper.temp import TMP_DIR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to understand these formulars if your after a grasp of the fundementals \n",
    "# but don't worry to much if your intrested in the concepts. Most ML tools abstract\n",
    "# these sort of functions away from you anyway.\n",
    "\n",
    "def hypothesis(x, Theta):\n",
    "    return Theta[0] + sum((Theta[i + 1] * x[i] for i in xrange(len(x))))\n",
    "\n",
    "\n",
    "def cost(X, Y, Theta, regularization_parameter):\n",
    "    \"\"\"\n",
    "    The Regularization term penalizes higher order terms, this helps prevent over fitting.\n",
    "    If set to 0 this is the same as not regularizing as per the simple example\n",
    "    \"\"\"\n",
    "    guess = [hypothesis(x, Theta) for x in X]\n",
    "    fit_cost = sum(((y - h) ** 2 for h, y in zip(guess, Y))) / len(X)\n",
    "    reg_cost = regularization_parameter * sum((t * t for t in Theta[1:])) / len(x)\n",
    "    return fit_cost + reg_cost\n",
    "\n",
    "\n",
    "def partial_derivative(X, Y, Theta, regularization_parameter):\n",
    "    \"\"\"\n",
    "    The Regularization term penalizes higher order terms, this helps prevent over fitting.\n",
    "    If set to 0 this is the same as not regularizing as per the simple example\n",
    "    \"\"\"\n",
    "    delta = [0 for i in xrange(len(Theta))]\n",
    "    delta[0] = sum([-(Y[i] - hypothesis(X[i], Theta)) for i in xrange(len(X))])\n",
    "    for i, x in enumerate(X):\n",
    "        for j, xj in enumerate(x):\n",
    "            delta[j + 1] += -xj * (Y[i] - hypothesis(x, Theta)) + regularization_parameter * Theta[j + 1]\n",
    "\n",
    "    delta = [2 / len(X) * delta[i] for i in xrange(len(delta))]\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing 3 hourly weather forecast from Met Office datapoint\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-09a9570533a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpoly_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# Using 2 or higher means we will us polynomial terms such as x^2 or x*y allowing more complicated functions to be predicted..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata_set_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mDATA_SET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthree_hourly_weather_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_term_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoly_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_SET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mbatching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# If batching is > 0 and <= len(X_train) we effectively use staccato gradient descent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/more/helper/data_helpers.pyc\u001b[0m in \u001b[0;36mthree_hourly_weather_data_set\u001b[0;34m(poly_term_order, max_total, no_cache)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeels_like_temp_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Processing data from, data point...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_total\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_total\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_total\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/more/helper/datapoint.pyc\u001b[0m in \u001b[0;36mfeels_like_temp_training_set\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Grabbing 3 hourly weather forecast from Met Office datapoint\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGET_ALL_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# The Met Office offer a `feels like temperature` forecast\n",
    "# See https://blog.metoffice.gov.uk/2012/02/15/what-is-feels-like-temperature/\n",
    "# We as an imaginary competitor we want to steel the algorithm for this.\n",
    "# We will use multivariate linear regression to calculate an approximation for us.\n",
    "# We will make the assumption that we can calculate feels like temperature based\n",
    "# on the other parameters the the Met Office proved in it's 5 day forecast.\n",
    "\n",
    "\n",
    "# Some set up params.\n",
    "alpha = 0.1  # Learning rate\n",
    "reg_param = 0  # regularization_parameter\n",
    "iterations = 500  # Number of training iterations\n",
    "poly_order = 2 # Using 2 or higher means we will us polynomial terms such as x^2 or x*y allowing more complicated functions to be predicted..\n",
    "data_set_size = 10000\n",
    "DATA_SET = data_helpers.three_hourly_weather_data_set(poly_term_order=poly_order, max_total=data_set_size)\n",
    "X_train, Y_train = DATA_SET['train']\n",
    "batching = len(X_train) // 10  # If batching is > 0 and <= len(X_train) we effectively use staccato gradient descent.\n",
    "batching = len(X_train) if batching < 1 or batching > len(X_train) else batching\n",
    "\n",
    "# Learning:\n",
    "Theta = [0 for i in xrange(len(X_train[0]) + 1)]  # Init all Theta to 0\n",
    "\n",
    "print \"Train over %s examples with in batches of %s running %s iterations. Alpha=%s, Reg = %s\" % (\n",
    "    len(X_train), batching, iterations, alpha, reg_param)\n",
    "\n",
    "print \"Start training @ %s \" % datetime.datetime.now()\n",
    "cost_history_over_training = []\n",
    "cost_history_over_training.append((0, cost(X_train, Y_train, Theta, reg_param)))\n",
    "for i in xrange(iterations):\n",
    "    if batching < len(X_train):\n",
    "        X_train, Y_train = data_helpers.shuffle(X_train, Y_train)\n",
    "    delta_theta = partial_derivative(X_train[:batching], Y_train[:batching], Theta, reg_param)\n",
    "    Theta = [theta - alpha * delta for theta, delta in zip(Theta, delta_theta)]\n",
    "    current_cost = cost(X_train, Y_train, Theta, reg_param)\n",
    "    cost_history_over_training.append((i + 1, current_cost))\n",
    "    if i % (iterations // 200 + 1) == 0:\n",
    "        print(\"Training step %d current cost %.2f\" % (i, current_cost))\n",
    "\n",
    "print \"Final cost is %.2f after %s iterations at learning rate %s\" % (current_cost, iterations, alpha)\n",
    "\n",
    "# Learning can take time so save our learnt data for use later\n",
    "pickled_model_file = os.path.join(TMP_DIR, \"a%s_r%s_i%s_b%s_p%s_d%s.Theta_min_max.pickle\" % (\n",
    "    alpha, reg_param, iterations, batching, poly_order, data_set_size))\n",
    "with open(pickled_model_file, 'w') as fp:\n",
    "    print \"Saving learnt model (Theta, norm_terms, poly_order) to: %s\" % pickled_model_file\n",
    "    cPickle.dump((Theta, DATA_SET['norm_terms'], poly_order), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validate and test the model\n",
    "print \"Validate/test:\"\n",
    "X_test, Y_test = DATA_SET['test']\n",
    "Y_test_predict = [hypothesis(x, Theta) for x in X_test]\n",
    "\n",
    "print \"Five guesses:\"\n",
    "guess_v_actual = zip(Y_test_predict, Y_test)\n",
    "random.shuffle(guess_v_actual)\n",
    "for guess, answer in guess_v_actual[:5]:\n",
    "    print(\"Predicted %.1f actual %s\" % (guess, answer))\n",
    "\n",
    "average_error = sum((math.sqrt((a - g) ** 2) for g, a in zip(Y_test_predict, Y_test))) / len(Y_test)\n",
    "print \"Over all the average error is %.3f\" % average_error\n",
    "\n",
    "print \"Show learning rate\"\n",
    "\n",
    "X, Y = zip(*cost_history_over_training)\n",
    "plt.plot(X, Y)\n",
    "plt.title('Gradient descent cost v iterations')\n",
    "plt.ylabel('Iterations')\n",
    "plt.xlabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This analysis can help find out how to improve our mode. It may take a while to run.\n",
    "# http://www.astroml.org/sklearn_tutorial/practical.html provieds some explination of learning curves (plotted below)\n",
    "# Any how/why you might use them\n",
    "train_cost = []\n",
    "real_cost = []\n",
    "num_data = []\n",
    "chart_filepath = None\n",
    "\n",
    "\n",
    "def trainWithNExamples(n, reg_param, itters=100):\n",
    "    X_subset = X_train[:n]\n",
    "    Y_subset = Y_train[:n]\n",
    "    T = [0 for i in xrange(len(X_train[0]) + 1)]\n",
    "    for i in xrange(itters):\n",
    "        delta_theta = partial_derivative(X_subset, Y_subset, T, reg_param)\n",
    "        T = [theta - alpha * delta for theta, delta in zip(T, delta_theta)]\n",
    "    return cost(X_subset, Y_subset, T, reg_param), T\n",
    "\n",
    "\n",
    "for i in xrange(1, 1001):\n",
    "    c, T = trainWithNExamples(i, reg_param)\n",
    "    c_validation = cost(X_test, Y_test, T, reg_param)\n",
    "    train_cost.append(c)\n",
    "    real_cost.append(c_validation)\n",
    "    num_data.append(i)\n",
    "    print \"With %s data cost %s real cost %s\" % (i, c, c_validation)\n",
    "    plt.plot(num_data, train_cost, label=\"Training\")\n",
    "    plt.plot(num_data, real_cost, label=\"Validation\")\n",
    "    plt.title('Learning curve')\n",
    "    plt.ylabel('Number of training samples')\n",
    "    plt.xlabel('Cost')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What now?\n",
    "* Can you improve the performance? Maybe tune params or by other methods.\n",
    "* Can you turn a different machine learning tool on this same data?\n",
    "* Can you learn the weather symobol based on the the other parameters?\n",
    "* Can you figure out what the formular we've come up with actually is?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
